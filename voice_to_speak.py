import sounddevice as sd
import numpy as np
import whisper
import scipy.signal
from scipy.signal import butter, filtfilt

# è¨­å®š
MIC_DEVICE = 5
SAMPLE_RATE = 44100
CHANNELS = 1
TARGET_RATE = 16000

# Whisperãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆç²¾åº¦é‡è¦–ã§baseãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰
print("ğŸ”„ Whisperãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
model = whisper.load_model("base")  # ç²¾åº¦å‘ä¸Šã®ãŸã‚baseãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
print("âœ… Whisperãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")

vad = webrtcvad.Vad(2)

def preprocess_audio_fast(audio, sr=16000):
    # 1) DC+æ­£è¦åŒ–+ã‚¯ãƒªãƒƒãƒ— ã‚’ä¸€æ‹¬
    mean = audio.mean()
    centered = ne.evaluate("audio - mean")
    rms = np.sqrt(np.mean(centered**2))
    if rms > 0:
        normed = ne.evaluate("centered * (0.1 / rms)")
    else:
        normed = centered
    clipped = np.clip(normed, -0.95, 0.95)
    
    # 2) SOSãƒãƒ³ãƒ‰ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿
    sos = butter(4, [80/sr*2, 7500/sr*2], btype='band', output='sos')
    filtered = sosfiltfilt(sos, clipped)
    
    # 3) VAD ãƒˆãƒªãƒŸãƒ³ã‚°
    # 16bit PCM ã«å¤‰æ›
    pcm16 = (filtered * 32767).astype('int16').tobytes()
    frame_bytes = int(sr * 0.03) * 2
    voiced = []
    for off in range(0, len(pcm16) - frame_bytes + 1, frame_bytes):
        chunk = pcm16[off:off+frame_bytes]
        if vad.is_speech(chunk, sr):
            voiced.append(chunk)
    if voiced:
        pcm_out = b''.join(voiced)
        return np.frombuffer(pcm_out, dtype='int16').astype('float32') / 32767
    else:
        return filtered

def record_audio(duration=5.0):
    """éŸ³å£°éŒ²éŸ³ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5ç§’ï¼‰"""
    duration = max(1.0, min(duration, 30.0))  # 1-30ç§’ã«åˆ¶é™
    
    print(f"ğŸ”´ {duration}ç§’é–“éŒ²éŸ³é–‹å§‹...")
    print("   â€» ãƒã‚¤ã‚¯ã«è¿‘ã¥ã„ã¦ã€ã¯ã£ãã‚Šã¨è©±ã—ã¦ãã ã•ã„")
    
    # éŒ²éŸ³å®Ÿè¡Œ
    audio = sd.rec(int(duration * SAMPLE_RATE), 
                   samplerate=SAMPLE_RATE, 
                   channels=CHANNELS, 
                   dtype='float32', 
                   device=MIC_DEVICE)
    sd.wait()
    
    # ãƒ¢ãƒãƒ©ãƒ«åŒ–
    if audio.ndim > 1:
        audio = np.mean(audio, axis=1)
    
    # 16kHzã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    if SAMPLE_RATE != TARGET_RATE:
        audio = scipy.signal.resample(audio, int(len(audio) * TARGET_RATE / SAMPLE_RATE))
    
    return audio.astype(np.float32)

def transcribe_audio(audio_data):
    """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æ–‡å­—èµ·ã“ã—"""
    if len(audio_data) == 0:
        return "éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™"
    
    print("ğŸ“ æ–‡å­—èµ·ã“ã—ä¸­...")
    
    # éŸ³å£°å‰å‡¦ç†
    processed_audio = preprocess_audio(audio_data)
    
    # éŸ³å£°ãƒ¬ãƒ™ãƒ«ãƒã‚§ãƒƒã‚¯
    rms = np.sqrt(np.mean(processed_audio**2))
    duration = len(processed_audio) / TARGET_RATE
    
    print(f"ğŸ” å‡¦ç†å¾ŒéŸ³å£°: {duration:.1f}ç§’, RMS: {rms:.4f}")
    
    if rms < 0.001 or duration < 0.3:
        return "éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼ˆéŸ³é‡ã‚’ä¸Šã’ã‚‹ã‹ã€ã‚ˆã‚Šé•·ãè©±ã—ã¦ãã ã•ã„ï¼‰"
    
    # Whisperã§æ–‡å­—èµ·ã“ã—ï¼ˆç²¾åº¦å‘ä¸Šã®ãŸã‚ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    result = model.transcribe(
        processed_audio, 
        language="ja", 
        fp16=False,
        temperature=0.0,        # æ±ºå®šçš„ãªå‡ºåŠ›ï¼ˆãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’æ’é™¤ï¼‰
        beam_size=5,           # ãƒ“ãƒ¼ãƒ æ¢ç´¢ã§ç²¾åº¦å‘ä¸Š
        best_of=5,             # è¤‡æ•°å€™è£œã‹ã‚‰æœ€è‰¯ã‚’é¸æŠ
        patience=1.0,          # ã‚ˆã‚Šé•·ã„æ¢ç´¢
        condition_on_previous_text=False,  # å‰ã®ãƒ†ã‚­ã‚¹ãƒˆã«ä¾å­˜ã—ãªã„
        initial_prompt="ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚",  # æ—¥æœ¬èªèªè­˜ã®ãƒ’ãƒ³ãƒˆ
        suppress_tokens=[-1]   # ä¸è¦ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŠ‘åˆ¶
    )
    
    text = result["text"].strip()
    
    # çµæœã®å“è³ªãƒã‚§ãƒƒã‚¯
    if not text:
        return "éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ"
    
    return text

def main():
    try:
        print("ğŸ™ï¸ é«˜ç²¾åº¦éŸ³å£°èªè­˜ãƒ—ãƒ­ã‚°ãƒ©ãƒ ")
        print("=" * 40)
        
        # éŒ²éŸ³æ™‚é–“ã®å…¥åŠ›
        try:
            duration = float(input("éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰[ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5]: ") or "5")
        except ValueError:
            duration = 5.0
        
        # éŒ²éŸ³ã¨æ–‡å­—èµ·ã“ã—
        audio = record_audio(duration)
        text = transcribe_audio(audio)
        
        print(f"\nâœ… èªè­˜çµæœ: ã€Œ{text}ã€")
        
    except KeyboardInterrupt:
        print("\nä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()